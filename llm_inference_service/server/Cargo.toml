[package]
name = "server"
version = "0.1.0"
edition = "2021"

[dependencies]
# Candle - ML framework
# 1 candle-core = { version = "0.8", features = ["cuda"] }
# 1 candle-transformers = "0.8"
# 1 candle-nn = "0.8"

candle-core = { git = "https://github.com/huggingface/candle.git", features = ["cuda"] }
candle-nn = { git = "https://github.com/huggingface/candle.git", features = ["cuda"] }
candle-transformers = { git = "https://github.com/huggingface/candle.git", features = ["cuda"] }

# tokenizers = { version = "0.19" }

# HTTP server
axum = "0.7"
tokio = { version = "1", features = ["full"] }
tower-http = { version = "0.5", features = ["cors"] }

# Serialization
serde = { version = "1.0", features = ["derive"] }
serde_json = "1.0"

# Utilities
anyhow = "1.0"
thiserror = "1.0"
tracing = "0.1"
tracing-subscriber = { version = "0.3", features = ["env-filter"] }

# Model loading
hf-hub = "0.3"
tokenizers = { version = "0.15", features = ["http"] }
futures = "0.3.31"
tokio-stream = "0.1.17"

[profile.release]
opt-level = 3
lto = true
codegen-units = 1
